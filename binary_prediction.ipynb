{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier #RandomizedLasso\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(string_seed):\n",
    "    result = \"\"\n",
    "    for char in string_seed:\n",
    "        if char.isdigit():\n",
    "            result += char\n",
    "    return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2018():\n",
    "    ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "    ext_data_team = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR']\n",
    "    \n",
    "    train = pd.read_csv('train_2010_2017.csv')\n",
    "    #train = train.drop(labels=ext_data_matchups, axis=1)\n",
    "    #train['TeamSeed'] = train['TeamSeed'].apply(fix_seed)\n",
    "    #train['OppTeamSeed'] = train['OppTeamSeed'].apply(fix_seed)\n",
    "    \n",
    "    train_Y = train['Outcome']\n",
    "    train_X = train.drop(labels=['Outcome'], axis=1)\n",
    "    \n",
    "    team_data = pd.read_csv('team_info_2018.csv')\n",
    "    #team_data = team_data.drop(labels=ext_data_team, axis=1)\n",
    "    #team_data['Seed'] = team_data['Seed'].apply(fix_seed)\n",
    "    \n",
    "    return train_X, train_Y, team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2017():\n",
    "    ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "    ext_data_team = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR']\n",
    "    \n",
    "    train = pd.read_csv('train_2010_2016.csv')\n",
    "    #train = train.drop(labels=ext_data_matchups, axis=1)\n",
    "    #train['TeamSeed'] = train['TeamSeed'].apply(fix_seed)\n",
    "    #train['OppTeamSeed'] = train['OppTeamSeed'].apply(fix_seed)\n",
    "    \n",
    "    train_Y = train['Outcome']\n",
    "    train_X = train.drop(labels=['Outcome'], axis=1)\n",
    "    \n",
    "    team_data = pd.read_csv('team_info_2017.csv')\n",
    "    #team_data = team_data.drop(labels=ext_data_team, axis=1)\n",
    "    #team_data['Seed'] = team_data['Seed'].apply(fix_seed)\n",
    "    \n",
    "    return train_X, train_Y, team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coef(lr, train_X):\n",
    "    adj = []\n",
    "    coefs = lr.coef_\n",
    "    for c in coefs[0]:\n",
    "        adj.append(math.exp(c))\n",
    "\n",
    "    features = pd.DataFrame(data=list(train_X))\n",
    "    weights = pd.DataFrame(data=adj)\n",
    "\n",
    "    feature_weights = pd.concat([features, weights], axis=1)\n",
    "    feature_weights.columns = ['Feature', 'Weight']\n",
    "    feature_weights = feature_weights.sort_values(by='Weight', ascending=False)\n",
    "    return feature_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions for matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winners_to_matchups(winners):\n",
    "    matchups = []\n",
    "    for i in xrange(0,len(winners),2):\n",
    "        team1 = winners[i]\n",
    "        team2 = winners[i+1]\n",
    "        matchups.append([team1, team2])\n",
    "    return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchups(team_data, pairings, rd, season):\n",
    "    opp_prefixes = ['Season', 'OppTeamID', 'OppW', 'OppL', 'OppAvgScore', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF', 'OppSeed']\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    \n",
    "    for p in pairings:        \n",
    "        team_1 = p[0]\n",
    "        team_1_data = team_data[(team_data['Season'] == season) & (team_data['TeamID'] == team_1)]\n",
    "        team_1_data_opp = team_1_data.copy()\n",
    "        team_1_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team_2 = p[1]\n",
    "        team_2_data = team_data[(team_data['Season'] == season) & (team_data['TeamID'] == team_2)]\n",
    "        team_2_data_opp = team_2_data.copy()\n",
    "        team_2_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team1_v_team2 = team_1_data.merge(team_2_data_opp, how='outer', on='Season')\n",
    "        team2_v_team1 = team_2_data.merge(team_1_data_opp, how='outer', on='Season')\n",
    "        \n",
    "        df1 = df1.append(team1_v_team2, ignore_index=True)\n",
    "        df2 = df2.append(team2_v_team1, ignore_index=True)\n",
    "        \n",
    "    df = df1.append(df2, ignore_index=True)\n",
    "    df['Round'] = rd\n",
    "    df = df.rename(columns={'Seed': 'TeamSeed', 'OppSeed': 'OppTeamSeed', 'AvgScore': 'AvgPoints', 'AvgOppScore': 'AvgOppPoints', 'OppAvgScore': 'OppAvgPoints'})\n",
    "    df = df[['Season', 'Round', 'TeamID', 'OppTeamID', 'TeamSeed', 'OppTeamSeed', 'W', 'L', 'AvgPoints', 'AvgFGM', 'AvgFGA', 'AvgFGM3', 'AvgFGA3', 'AvgFTM', 'AvgFTA', 'AvgOR', 'AvgDR', 'AvgAst', 'AvgTO', 'AvgStl', 'AvgBlk', 'AvgPF', 'AvgOppPoints', 'AvgOppFGM', 'AvgOppFGA', 'AvgOppFGM3', 'AvgOppFGA3', 'AvgOppFTM', 'AvgOppFTA', 'AvgOppOR', 'AvgOppDR', 'AvgOppAst', 'AvgOppTO', 'AvgOppStl', 'AvgOppBlk', 'AvgOppPF', 'OppW', 'OppL', 'OppAvgPoints', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline predictor - always pick higher seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_predictor(matchups):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for m in matchups:\n",
    "        team1 = m[0]\n",
    "        team2 = m[1]\n",
    "        \n",
    "        seed1 = seeds_dict[team1]\n",
    "        seed2 = seeds_dict[team2]\n",
    "        \n",
    "        if (seed1 > seed2):\n",
    "            winners.append(team2)\n",
    "            losers.append(team1)\n",
    "        else:\n",
    "            winners.append(team1)\n",
    "            losers.append(team2)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_baseline(matchups):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        (loser_ids, winner_ids) = baseline_predictor(matchups)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "        \n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal probability-based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_prob(classifier, matchups):\n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "\n",
    "    # make predictions\n",
    "    results_concat['Team1WinPred'] = np.where(results_concat['Win1Adj'] > results_concat['Win2Adj'], 1, 0)\n",
    "    # print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team2'], results_concat['Team1'])\n",
    "    return pred_losers, pred_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_first_round(classifier, matchups):\n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "\n",
    "    # make predictions\n",
    "    results_concat['Team1WinPred'] = np.where(results_concat['Win1Adj'] > results_concat['Win2Adj'], 1, 0)\n",
    "    \n",
    "    results = results_concat['Team1WinPred'].values.tolist()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket(team_data, matchups, classifier, season):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r, season)\n",
    "        (loser_ids, winner_ids) = predict_with_prob(classifier, matchups_with_data)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction with upset bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_upset_bonus(classifier, matchups, round_num):\n",
    "    points = {1:1, 2:2, 3:4, 4:8, 5:16, 6:32}\n",
    "    upset_bonus = 2\n",
    "    round_points = points[round_num]\n",
    "    \n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "    \n",
    "    # calculate expected values\n",
    "    results_concat['Team1Seed'] = results_concat['Team1'].map(seeds_dict)\n",
    "    results_concat['Team2Seed'] = results_concat['Team2'].map(seeds_dict)\n",
    "    \n",
    "    results_concat['Team1WinVal'] = np.where(results_concat['Team1Seed'] > results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    results_concat['Team2WinVal'] = np.where(results_concat['Team1Seed'] < results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    \n",
    "    results_concat['Team1ExpVal'] = results_concat['Win1Adj'] * results_concat['Team1WinVal']\n",
    "    results_concat['Team2ExpVal'] = results_concat['Win2Adj'] * results_concat['Team2WinVal']\n",
    "    \n",
    "    #results_concat = results_concat[['Team1', 'Win1Adj', 'Team1Seed', 'Team1WinVal', 'Team1ExpVal', 'Team2', 'Win2Adj', 'Team2Seed', 'Team2WinVal', 'Team2ExpVal']]\n",
    "    #print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1ExpVal'] > results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1ExpVal'] < results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    return pred_winners, pred_losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_upsets(team_data, matchups, classifier, season):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r, season)\n",
    "        (loser_ids, winner_ids) = predict_with_upset_bonus(classifier, matchups_with_data, r)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_upsets(results, pred_winners, pred_losers):\n",
    "    # see https://www.nytimes.com/2015/03/16/upshot/heres-how-our-ncaa-bracket-works.html\n",
    "    points = [1, 2, 4, 8, 16, 32]\n",
    "    total_pts = 0\n",
    "    upset_bonus = 5\n",
    "    num_upsets = 0\n",
    "    \n",
    "    for rd, pts, pred_win, pred_lose, act_win in zip(rounds, points, pred_winners, pred_losers, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred_w, pred_l, act_w in zip(pred_win, pred_lose, act_win):\n",
    "            if (pred_w == act_w):\n",
    "                num_correct += 1\n",
    "                if (seeds_dict[pred_w] > seeds_dict[pred_l]):\n",
    "                    num_upsets += 1\n",
    "                \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    total_pts += (num_upsets * upset_bonus)\n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_espn(results, prediction):\n",
    "    # see http://games.espn.com/tournament-challenge-bracket/2018/en/story?pageName=tcmen%5Chowtoplay\n",
    "    points = [10, 20, 40, 80, 160, 320]\n",
    "    total_pts = 0\n",
    "    \n",
    "    for rd, pts, pred_winners, act_winners in zip(rounds, points, prediction, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred, act in zip(pred_winners, act_winners):\n",
    "            if (pred == act):\n",
    "                num_correct += 1\n",
    "        \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y, team_data) = load_data_2018()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]    \n",
    "tournament_results = [[1420, 1243, 1246, 1138, 1260, 1397, 1305, 1153, 1462, 1199, 1326, 1211, 1222, 1276, 1401, 1314, 1437, 1104, 1452, 1267, 1196, 1403, 1139, 1345, 1242, 1371, 1155, 1120, 1393, 1277, 1348, 1181],[1243, 1246, 1260, 1305, 1199, 1211, 1276, 1401, 1437, 1452, 1403, 1345, 1242, 1155, 1393, 1181],[1243, 1260, 1199, 1276, 1437, 1403, 1242, 1181],[1260, 1276, 1437, 1242],[1276, 1437],[1437]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2018]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "classifiers = [\n",
    "            GaussianNB(), \\\n",
    "            LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "            LogisticRegression(), \\\n",
    "            SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            DecisionTreeClassifier(), \\\n",
    "            RandomForestClassifier(),  \\\n",
    "            BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "            GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "            MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "(baseline_losers, baseline_winners) = predict_bracket_baseline(matchups)\n",
    "baseline_winner = team_dict[baseline_winners[5][0]]\n",
    "baseline_espn_score = score_bracket_espn(tournament_results, baseline_winners)\n",
    "baseline_upset_score = score_bracket_upsets(tournament_results, baseline_winners, baseline_losers)\n",
    "results.append([\"Baseline\", baseline_winner, baseline_espn_score, baseline_upset_score])\n",
    "\n",
    "for m,c in zip(models,classifiers):\n",
    "    c.fit(train_X, train_Y)\n",
    "    (losers, winners) = predict_bracket(team_data, matchups, c, 2018)\n",
    "    \n",
    "    champion = team_dict[winners[5][0]]\n",
    "    espn_score = score_bracket_espn(tournament_results, winners)\n",
    "    upset_score = score_bracket_upsets(tournament_results, winners, losers)\n",
    "    \n",
    "    results.append([m, champion, espn_score, upset_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tabulate.tabulate(results, headers=['Model', 'Champion', 'ESPN Score', 'Upset Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()\n",
    "#lr.fit(train_X, train_Y)\n",
    "#(losers, winners) = predict_bracket_upsets(team_data, matchups, lr, 2018)\n",
    "#upset_score = score_bracket_upsets(results, winners, losers)\n",
    "#print upset_score\n",
    "#espn_score = score_bracket_espn(results, winners)\n",
    "#print espn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X_2017, train_Y_2017, team_data_2017) = load_data_2017()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "matchups_2017 = [[1437, 1291], [1458, 1439], [1438, 1423], [1196, 1190], [1374, 1425], [1124, 1308], [1376, 1266], [1181, 1407], [1211, 1355], [1321, 1435], [1323, 1343], [1452, 1137], [1268, 1462], [1199, 1195], [1388, 1433], [1112, 1315], [1242, 1413], [1274, 1277], [1235, 1305], [1345, 1436], [1166, 1348], [1332, 1233], [1276, 1329], [1257, 1240], [1314, 1411], [1116, 1371], [1278, 1292], [1139, 1457], [1153, 1243], [1417, 1245], [1173, 1455], [1246, 1297]]\n",
    "tournament_results_2017 = [[1437, 1458, 1438, 1196, 1425, 1124, 1376, 1181, 1211, 1321, 1323, 1452, 1462, 1199, 1388, 1112, 1242, 1277, 1235, 1345, 1348, 1332, 1276, 1257, 1314, 1116, 1292, 1139, 1153, 1417, 1455, 1246], [1458, 1196, 1124, 1376, 1211, 1452, 1462, 1112, 1242, 1345, 1332, 1276, 1314, 1139, 1417, 1246], [1196, 1376, 1211, 1462, 1242, 1332, 1314, 1246], [1376, 1211, 1332, 1314], [1211, 1314], [1314]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2017]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "classifiers = [\n",
    "            GaussianNB(), \\\n",
    "            LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "            LogisticRegression(), \\\n",
    "            SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            DecisionTreeClassifier(), \\\n",
    "            RandomForestClassifier(),  \\\n",
    "            BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "            GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "            MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2017 = []\n",
    "\n",
    "(baseline_losers, baseline_winners) = predict_bracket_baseline(matchups_2017)\n",
    "baseline_winner = team_dict[baseline_winners[5][0]]\n",
    "baseline_espn_score = score_bracket_espn(tournament_results_2017, baseline_winners)\n",
    "baseline_upset_score = score_bracket_upsets(tournament_results_2017, baseline_winners, baseline_losers)\n",
    "results_2017.append([\"Baseline\", baseline_winner, baseline_espn_score, baseline_upset_score])\n",
    "\n",
    "for m,c in zip(models,classifiers):\n",
    "    c.fit(train_X_2017, train_Y_2017)\n",
    "    (losers, winners) = predict_bracket(team_data_2017, matchups_2017, c, 2017)\n",
    "    \n",
    "    champion = team_dict[winners[5][0]]\n",
    "    espn_score = score_bracket_espn(tournament_results_2017, winners)\n",
    "    upset_score = score_bracket_upsets(tournament_results_2017, winners, losers)\n",
    "    \n",
    "    results_2017.append([m, champion, espn_score, upset_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tabulate.tabulate(results_2017, headers=['Model', 'Champion', 'ESPN Score', 'Upset Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = pd.DataFrame(results_2017, columns=['Model', '2017 Winner', '2017 ESPN Score', '2017 Upset Score'])\n",
    "df_2018 = pd.DataFrame(results, columns=['Model', '2018 Winner', '2018 ESPN Score', '2018 Upset Score'])\n",
    "df = df_2017.merge(df_2018, on='Model')\n",
    "df = df[['Model', '2017 Winner', '2018 Winner', '2017 ESPN Score', '2018 ESPN Score', '2017 Upset Score', '2018 Upset Score']]\n",
    "#print df.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict first round results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_test(x_data, x_labels, y_data, y_labels):\n",
    "    starttime = time.time()\n",
    "\n",
    "    # binary models\n",
    "    models = [\"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "    clfs = [\n",
    "                GaussianNB(), \\\n",
    "                LinearDiscriminantAnalysis(), \\\n",
    "                svm.SVC(kernel = 'linear', probability=True), \\\n",
    "                neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "                LogisticRegression(), \\\n",
    "                SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "                AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "                DecisionTreeClassifier(), \\\n",
    "                RandomForestClassifier(),  \\\n",
    "                BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "                ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "                GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "                MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(clfs)):\n",
    "        print \"model being tested: {0}\".format(models[i])\n",
    "        time_start = time.time()\n",
    "        clf = clfs[i].fit(x_data, x_labels)\n",
    "        predict = predict_first_round(clf, y_data)\n",
    "        runtime = time.time() - time_start\n",
    "        a = metrics.accuracy_score(y_labels, predict)\n",
    "\n",
    "        results.append([models[i], a])\n",
    "    print tabulate.tabulate(results, headers=['Model', 'Accuracy'])\n",
    "    print \"Binary test took {0} secs\".format(time.time() - starttime)\n",
    "    return pd.DataFrame(data=results, columns=['Model', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict 2018 first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X_2018, train_Y_2018, team_data_2018) = load_data_2018()\n",
    "\n",
    "test_2018 = pd.read_csv('test_2018.csv')\n",
    "ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "test_2018 = test_2018.drop(ext_data_matchups, axis=1)  \n",
    "test_2018['TeamSeed'] = test_2018['TeamSeed'].apply(fix_seed)\n",
    "test_2018['OppTeamSeed'] = test_2018['OppTeamSeed'].apply(fix_seed)\n",
    "test_Y_2018 = test_2018['Outcome'][0:32]\n",
    "test_X_2018 = test_2018.drop(['Outcome'], axis=1)\n",
    "\n",
    "fr_2018 = bin_test(train_X_2018, train_Y_2018, test_X_2018, test_Y_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr_2018 = fr_2018.round(decimals=3)\n",
    "#df = df.merge(fr_2018, on='Model')\n",
    "#df.columns = ['Model', '2017 Winner', '2018 Winner', '2017 ESPN Score', '2018 ESPN Score', '2017 Upset Score', '2018 Upset Score', '2018 FR Accuracy']\n",
    "#print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict 2017 first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_2017_matchups = create_matchups(team_data_2017, matchups_2017, 1, 2017)\n",
    "\n",
    "fr_2017_winners = tournament_results_2017[0]\n",
    "\n",
    "outcomes = []\n",
    "teams = fr_2017_matchups['TeamID'].values.tolist()\n",
    "for t in teams:\n",
    "    if t in fr_2017_winners:\n",
    "        outcomes.append(1)\n",
    "    else:\n",
    "        outcomes.append(0)\n",
    "        \n",
    "outcomes = outcomes[:32]\n",
    "\n",
    "fr_2017 = bin_test(train_X_2017, train_Y_2017, fr_2017_matchups, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr_2017 = fr_2017.round(decimals=3)\n",
    "#df = df.merge(fr_2017, on='Model')\n",
    "#df.columns = ['Model', '2017 Winner', '2018 Winner', '2017 ESPN Score', '2018 ESPN Score', '2017 Upset Score', '2018 Upset Score', '2018 FR Acc', '2017 FR Acc']\n",
    "#print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print df.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check LR coefficients for 2018 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_X, train_Y, team_data) = load_data_2018()\n",
    "#scaled_X = StandardScaler().fit_transform(train_X)\n",
    "#lr = LogisticRegression()\n",
    "#lr.fit(scaled_X, train_Y)\n",
    "#weights = check_coef(lr, train_X)\n",
    "#print weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(x_data, x_labels, y_data, y_labels):\n",
    "    starttime = time.time()\n",
    "\n",
    "    # binary models\n",
    "    models = [\"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "    clfs = [\n",
    "                GaussianNB(), \\\n",
    "                LinearDiscriminantAnalysis(), \\\n",
    "                svm.SVC(kernel = 'linear', probability=True), \\\n",
    "                neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "                LogisticRegression(), \\\n",
    "                SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "                AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "                DecisionTreeClassifier(), \\\n",
    "                RandomForestClassifier(),  \\\n",
    "                BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "                ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "                GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "                MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]\n",
    "\n",
    "    misclassified = dict.fromkeys(range(0, 33), 0)\n",
    "    \n",
    "    for i in range(len(clfs)):\n",
    "        print \"model being tested: {0}\".format(models[i])\n",
    "        time_start = time.time()\n",
    "        clf = clfs[i].fit(x_data, x_labels)\n",
    "        predict = predict_first_round(clf, y_data)\n",
    "        \n",
    "        i = 0\n",
    "        for p,l in zip(predict, y_labels):\n",
    "            if (p != l):\n",
    "                misclassified[i] += 1\n",
    "            i += 1\n",
    "            \n",
    "    return misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model being tested: GNB\n",
      "model being tested: LDA\n",
      "model being tested: SVM_L\n",
      "model being tested: 5NN\n",
      "model being tested: LR2\n",
      "model being tested: SGD\n",
      "model being tested: ADA\n",
      "model being tested: DT\n",
      "model being tested: RF\n",
      "model being tested: DPGMM\n",
      "model being tested: ET\n",
      "model being tested: GMM\n",
      "model being tested: MLP\n"
     ]
    }
   ],
   "source": [
    "(train_X_2018, train_Y_2018, team_data_2018) = load_data_2018()\n",
    "\n",
    "test_2018 = pd.read_csv('test_2018.csv')\n",
    "ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "test_2018 = test_2018.drop(ext_data_matchups, axis=1)  \n",
    "test_2018['TeamSeed'] = test_2018['TeamSeed'].apply(fix_seed)\n",
    "test_2018['OppTeamSeed'] = test_2018['OppTeamSeed'].apply(fix_seed)\n",
    "test_Y_2018 = test_2018['Outcome'][0:32]\n",
    "test_X_2018 = test_2018.drop(['Outcome'], axis=1)\n",
    "\n",
    "outliers_fr_2018 = find_outliers(train_X_2018, train_Y_2018, test_X_2018, test_Y_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: 0\n",
      "15: 1\n",
      "2: 2\n",
      "8: 2\n",
      "17: 2\n",
      "19: 2\n",
      "24: 2\n",
      "4: 3\n",
      "5: 3\n",
      "7: 3\n",
      "9: 3\n",
      "13: 3\n",
      "22: 3\n",
      "25: 3\n",
      "26: 3\n",
      "29: 3\n",
      "31: 3\n",
      "1: 4\n",
      "3: 4\n",
      "30: 4\n",
      "6: 5\n",
      "10: 5\n",
      "21: 5\n",
      "27: 6\n",
      "14: 7\n",
      "23: 7\n",
      "0: 8\n",
      "16: 8\n",
      "28: 8\n",
      "11: 11\n",
      "12: 11\n",
      "18: 12\n",
      "20: 13\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(outliers_fr_2018.iteritems(), key=lambda (k,v): (v,k)):\n",
    "    print \"%s: %s\" % (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlier data\n",
    "# 1 12 13 15 17 19 21 24 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model being tested: GNB\n",
      "9\n",
      "model being tested: LDA\n",
      "9\n",
      "model being tested: SVM_L\n",
      "9\n",
      "model being tested: 5NN\n",
      "9\n",
      "model being tested: LR2\n",
      "9\n",
      "model being tested: SGD\n",
      "9\n",
      "model being tested: ADA\n",
      "9\n",
      "model being tested: DT\n",
      "9\n",
      "model being tested: RF\n",
      "9\n",
      "model being tested: DPGMM\n",
      "9\n",
      "model being tested: ET\n",
      "9\n",
      "model being tested: GMM\n",
      "9\n",
      "model being tested: MLP\n",
      "9\n",
      "Model      Accuracy\n",
      "-------  ----------\n",
      "GNB        0.777778\n",
      "LDA        0.888889\n",
      "SVM_L      0.888889\n",
      "5NN        0.666667\n",
      "LR2        0.888889\n",
      "SGD        0.111111\n",
      "ADA        0.777778\n",
      "DT         0.666667\n",
      "RF         0.888889\n",
      "DPGMM      0.222222\n",
      "ET         0.777778\n",
      "GMM        0.444444\n",
      "MLP        0.777778\n",
      "Binary test took 67.5949790478 secs\n",
      "    Model  Accuracy\n",
      "0     GNB     0.778\n",
      "1     LDA     0.889\n",
      "2   SVM_L     0.889\n",
      "3     5NN     0.667\n",
      "4     LR2     0.889\n",
      "5     SGD     0.111\n",
      "6     ADA     0.778\n",
      "7      DT     0.667\n",
      "8      RF     0.889\n",
      "9   DPGMM     0.222\n",
      "10     ET     0.778\n",
      "11    GMM     0.444\n",
      "12    MLP     0.778\n"
     ]
    }
   ],
   "source": [
    "(train_X_2018, train_Y_2018, team_data_2018) = load_data_2018()\n",
    "\n",
    "test_2018_outliers = pd.read_csv('test_2018_outliers.csv')\n",
    "ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "test_2018_outliers = test_2018_outliers.drop(ext_data_matchups, axis=1)  \n",
    "test_2018_outliers['TeamSeed'] = test_2018_outliers['TeamSeed'].apply(fix_seed)\n",
    "test_2018_outliers['OppTeamSeed'] = test_2018_outliers['OppTeamSeed'].apply(fix_seed)\n",
    "test_Y_2018 = test_2018_outliers['Outcome'][0:9]\n",
    "test_X_2018 = test_2018_outliers.drop(['Outcome'], axis=1)\n",
    "\n",
    "fr_2018_outliers = bin_test(train_X_2018, train_Y_2018, test_X_2018, test_Y_2018)\n",
    "fr_2018_outliers = fr_2018_outliers.round(decimals=3)\n",
    "print fr_2018_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      " Model &  Accuracy \\\\\n",
      "\\midrule\n",
      "   GNB &     0.778 \\\\\n",
      "   LDA &     0.889 \\\\\n",
      " SVM\\_L &     0.889 \\\\\n",
      "   5NN &     0.667 \\\\\n",
      "   LR2 &     0.889 \\\\\n",
      "   SGD &     0.111 \\\\\n",
      "   ADA &     0.778 \\\\\n",
      "    DT &     0.667 \\\\\n",
      "    RF &     0.889 \\\\\n",
      " DPGMM &     0.222 \\\\\n",
      "    ET &     0.778 \\\\\n",
      "   GMM &     0.444 \\\\\n",
      "   MLP &     0.778 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print fr_2018_outliers.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_names = ['LDA', 'SVM_L', 'LR2', 'RF', 'ADA', 'ET']\n",
    "ens_clfs = [LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            LogisticRegression(), \\\n",
    "            RandomForestClassifier(), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4)\n",
    "           ]\n",
    "\n",
    "ens_models = []\n",
    "for n,c in zip(ens_names, ens_clfs):\n",
    "    ens_models.append([n,c])\n",
    "    \n",
    "ens_clf = VotingClassifier(ens_models, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y, team_data) = load_data_2018()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]    \n",
    "tournament_results = [[1420, 1243, 1246, 1138, 1260, 1397, 1305, 1153, 1462, 1199, 1326, 1211, 1222, 1276, 1401, 1314, 1437, 1104, 1452, 1267, 1196, 1403, 1139, 1345, 1242, 1371, 1155, 1120, 1393, 1277, 1348, 1181],[1243, 1246, 1260, 1305, 1199, 1211, 1276, 1401, 1437, 1452, 1403, 1345, 1242, 1155, 1393, 1181],[1243, 1260, 1199, 1276, 1437, 1403, 1242, 1181],[1260, 1276, 1437, 1242],[1276, 1437],[1437]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2018]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Villanova\n",
      "1100\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "ens_clf.fit(train_X, train_Y)\n",
    "(losers, winners) = predict_bracket(team_data, matchups, ens_clf, 2018)\n",
    "\n",
    "champion = team_dict[winners[5][0]]\n",
    "print champion\n",
    "espn_score = score_bracket_espn(tournament_results, winners)\n",
    "print espn_score\n",
    "upset_score = score_bracket_upsets(tournament_results, winners, losers)\n",
    "print upset_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "test_2018 = pd.read_csv('test_2018.csv')\n",
    "ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "test_2018 = test_2018.drop(ext_data_matchups, axis=1)  \n",
    "test_2018['TeamSeed'] = test_2018['TeamSeed'].apply(fix_seed)\n",
    "test_2018['OppTeamSeed'] = test_2018['OppTeamSeed'].apply(fix_seed)\n",
    "test_Y_2018 = test_2018['Outcome'][0:32]\n",
    "test_X_2018 = test_2018.drop(['Outcome'], axis=1)\n",
    "\n",
    "predict = predict_first_round(ens_clf, test_X_2018)\n",
    "a = metrics.accuracy_score(test_Y_2018, predict)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_names = ['LDA', 'SVM_L', 'LR2', 'RF', 'ADA', 'ET']\n",
    "ens_clfs = [LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            LogisticRegression(), \\\n",
    "            RandomForestClassifier(), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4)\n",
    "           ]\n",
    "\n",
    "ens_models = []\n",
    "for n,c in zip(ens_names, ens_clfs):\n",
    "    ens_models.append([n,c])\n",
    "    \n",
    "ens_clf = VotingClassifier(ens_models, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X_2017, train_Y_2017, team_data_2017) = load_data_2017()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "matchups_2017 = [[1437, 1291], [1458, 1439], [1438, 1423], [1196, 1190], [1374, 1425], [1124, 1308], [1376, 1266], [1181, 1407], [1211, 1355], [1321, 1435], [1323, 1343], [1452, 1137], [1268, 1462], [1199, 1195], [1388, 1433], [1112, 1315], [1242, 1413], [1274, 1277], [1235, 1305], [1345, 1436], [1166, 1348], [1332, 1233], [1276, 1329], [1257, 1240], [1314, 1411], [1116, 1371], [1278, 1292], [1139, 1457], [1153, 1243], [1417, 1245], [1173, 1455], [1246, 1297]]\n",
    "tournament_results_2017 = [[1437, 1458, 1438, 1196, 1425, 1124, 1376, 1181, 1211, 1321, 1323, 1452, 1462, 1199, 1388, 1112, 1242, 1277, 1235, 1345, 1348, 1332, 1276, 1257, 1314, 1116, 1292, 1139, 1153, 1417, 1455, 1246], [1458, 1196, 1124, 1376, 1211, 1452, 1462, 1112, 1242, 1345, 1332, 1276, 1314, 1139, 1417, 1246], [1196, 1376, 1211, 1462, 1242, 1332, 1314, 1246], [1376, 1211, 1332, 1314], [1211, 1314], [1314]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2017]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Villanova\n",
      "790\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "ens_clf.fit(train_X_2017, train_Y_2017)\n",
    "(losers, winners) = predict_bracket(team_data_2017, matchups_2017, ens_clf, 2017)\n",
    "\n",
    "champion = team_dict[winners[5][0]]\n",
    "print champion\n",
    "espn_score = score_bracket_espn(tournament_results_2017, winners)\n",
    "print espn_score\n",
    "upset_score = score_bracket_upsets(tournament_results_2017, winners, losers)\n",
    "print upset_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84375\n"
     ]
    }
   ],
   "source": [
    "fr_2017_matchups = create_matchups(team_data_2017, matchups_2017, 1, 2017)\n",
    "\n",
    "fr_2017_winners = tournament_results_2017[0]\n",
    "\n",
    "outcomes = []\n",
    "teams = fr_2017_matchups['TeamID'].values.tolist()\n",
    "for t in teams:\n",
    "    if t in fr_2017_winners:\n",
    "        outcomes.append(1)\n",
    "    else:\n",
    "        outcomes.append(0)\n",
    "        \n",
    "outcomes = outcomes[:32]\n",
    "\n",
    "predict = predict_first_round(ens_clf, fr_2017_matchups)\n",
    "a = metrics.accuracy_score(outcomes, predict)\n",
    "print a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
