{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import tabulate\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier #RandomizedLasso\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(string_seed):\n",
    "    result = \"\"\n",
    "    for char in string_seed:\n",
    "        if char.isdigit():\n",
    "            result += char\n",
    "    return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "    ext_data_team = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR']\n",
    "    \n",
    "    train = pd.read_csv('train_2010_2017.csv')\n",
    "    train = train.drop(labels=ext_data_matchups, axis=1)\n",
    "    train['TeamSeed'] = train['TeamSeed'].apply(fix_seed)\n",
    "    train['OppTeamSeed'] = train['OppTeamSeed'].apply(fix_seed)\n",
    "    \n",
    "    train_Y = train['Outcome']\n",
    "    train_X = train.drop(labels=['Outcome'], axis=1)\n",
    "    \n",
    "    team_data = pd.read_csv('team_info_2018.csv')\n",
    "    team_data = team_data.drop(labels=ext_data_team, axis=1)\n",
    "    team_data['Seed'] = team_data['Seed'].apply(fix_seed)\n",
    "    \n",
    "    return train_X, train_Y, team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coef(lr):\n",
    "    adj = []\n",
    "    coefs = lr.coef_\n",
    "    for c in coefs[0]:\n",
    "        adj.append(math.exp(c))\n",
    "\n",
    "    features = pd.DataFrame(data=list(test_X))\n",
    "    weights = pd.DataFrame(data=adj)\n",
    "\n",
    "    feature_weights = pd.concat([features, weights], axis=1)\n",
    "    feature_weights.columns = ['Feature', 'Weight']\n",
    "    feature_weights = feature_weights.sort_values(by='Weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions for matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winners_to_matchups(winners):\n",
    "    matchups = []\n",
    "    for i in xrange(0,len(winners),2):\n",
    "        team1 = winners[i]\n",
    "        team2 = winners[i+1]\n",
    "        matchups.append([team1, team2])\n",
    "    return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchups(team_data, pairings, round):\n",
    "    opp_prefixes = ['Season', 'OppTeamID', 'OppW', 'OppL', 'OppAvgScore', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF', 'OppSeed']\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    \n",
    "    for p in pairings:        \n",
    "        team_1 = p[0]\n",
    "        team_1_data = team_data[(team_data['Season'] == 2018) & (team_data['TeamID'] == team_1)]\n",
    "        team_1_data_opp = team_1_data.copy()\n",
    "        team_1_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team_2 = p[1]\n",
    "        team_2_data = team_data[(team_data['Season'] == 2018) & (team_data['TeamID'] == team_2)]\n",
    "        team_2_data_opp = team_2_data.copy()\n",
    "        team_2_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team1_v_team2 = team_1_data.merge(team_2_data_opp, how='outer', on='Season')\n",
    "        team2_v_team1 = team_2_data.merge(team_1_data_opp, how='outer', on='Season')\n",
    "        \n",
    "        df1 = df1.append(team1_v_team2, ignore_index=True)\n",
    "        df2 = df2.append(team2_v_team1, ignore_index=True)\n",
    "        \n",
    "    df = df1.append(df2, ignore_index=True)\n",
    "    df['Round'] = 1  \n",
    "    df = df.rename(columns={'Seed': 'TeamSeed', 'OppSeed': 'OppTeamSeed', 'AvgScore': 'AvgPoints', 'AvgOppScore': 'AvgOppPoints', 'OppAvgScore': 'OppAvgPoints'})\n",
    "    df = df[['Season', 'Round', 'TeamID', 'OppTeamID', 'TeamSeed', 'OppTeamSeed', 'W', 'L', 'AvgPoints', 'AvgFGM', 'AvgFGA', 'AvgFGM3', 'AvgFGA3', 'AvgFTM', 'AvgFTA', 'AvgOR', 'AvgDR', 'AvgAst', 'AvgTO', 'AvgStl', 'AvgBlk', 'AvgPF', 'AvgOppPoints', 'AvgOppFGM', 'AvgOppFGA', 'AvgOppFGM3', 'AvgOppFGA3', 'AvgOppFTM', 'AvgOppFTA', 'AvgOppOR', 'AvgOppDR', 'AvgOppAst', 'AvgOppTO', 'AvgOppStl', 'AvgOppBlk', 'AvgOppPF', 'OppW', 'OppL', 'OppAvgPoints', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline predictor - always pick higher seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_predictor(matchups):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for m in matchups:\n",
    "        team1 = m[0]\n",
    "        team2 = m[1]\n",
    "        \n",
    "        seed1 = seeds_dict[team1]\n",
    "        seed2 = seeds_dict[team2]\n",
    "        \n",
    "        if (seed1 < seed2):\n",
    "            winners.append(team1)\n",
    "            losers.append(team2)\n",
    "        else:\n",
    "            winners.append(team2)\n",
    "            losers.append(team1)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_baseline():\n",
    "    matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]\n",
    "    \n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        (loser_ids, winner_ids) = baseline_predictor(matchups)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        # print winner_names\n",
    "        # print\n",
    "        \n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal probability-based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_prob(classifier, matchups):\n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "\n",
    "    # make predictions\n",
    "    results_concat['Team1WinPred'] = np.where(results_concat['Win1Adj'] > results_concat['Win2Adj'], 1, 0)\n",
    "    # print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team2'], results_concat['Team1'])\n",
    "    return pred_losers, pred_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket(classifier):\n",
    "    matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r)\n",
    "        (loser_ids, winner_ids) = predict_with_prob(classifier, matchups_with_data)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction with upset bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_upset_bonus(classifier, matchups, round_num):\n",
    "    points = {1:1, 2:2, 3:4, 4:8, 5:16, 6:32}\n",
    "    upset_bonus = 2\n",
    "    round_points = points[round_num]\n",
    "    \n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "    \n",
    "    # calculate expected values\n",
    "    results_concat['Team1Seed'] = results_concat['Team1'].map(seeds_dict)\n",
    "    results_concat['Team2Seed'] = results_concat['Team2'].map(seeds_dict)\n",
    "    \n",
    "    results_concat['Team1WinVal'] = np.where(results_concat['Team1Seed'] > results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    results_concat['Team2WinVal'] = np.where(results_concat['Team1Seed'] < results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    \n",
    "    results_concat['Team1ExpVal'] = results_concat['Win1Adj'] * results_concat['Team1WinVal']\n",
    "    results_concat['Team2ExpVal'] = results_concat['Win2Adj'] * results_concat['Team2WinVal']\n",
    "    \n",
    "    #results_concat = results_concat[['Team1', 'Win1Adj', 'Team1Seed', 'Team1WinVal', 'Team1ExpVal', 'Team2', 'Win2Adj', 'Team2Seed', 'Team2WinVal', 'Team2ExpVal']]\n",
    "    #print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1ExpVal'] > results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1ExpVal'] < results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    return pred_winners, pred_losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_upsets(classifier):\n",
    "    matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r)\n",
    "        (loser_ids, winner_ids) = predict_with_upset_bonus(classifier, matchups_with_data, r)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_upsets(results, pred_winners, pred_losers):\n",
    "    # see https://www.nytimes.com/2015/03/16/upshot/heres-how-our-ncaa-bracket-works.html\n",
    "    points = [1, 2, 4, 8, 16, 32]\n",
    "    total_pts = 0\n",
    "    upset_bonus = 5\n",
    "    num_upsets = 0\n",
    "    \n",
    "    for rd, pts, pred_win, pred_lose, act_win in zip(rounds, points, pred_winners, pred_losers, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred_w, pred_l, act_w in zip(pred_win, pred_lose, act_win):\n",
    "            if (pred_w == act_w):\n",
    "                num_correct += 1\n",
    "                if (seeds_dict[pred_w] > seeds_dict[pred_l]):\n",
    "                    num_upsets += 1\n",
    "                \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    total_pts += (num_upsets * upset_bonus)\n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_espn(results, prediction):\n",
    "    # see http://games.espn.com/tournament-challenge-bracket/2018/en/story?pageName=tcmen%5Chowtoplay\n",
    "    points = [10, 20, 40, 80, 160, 320]\n",
    "    total_pts = 0\n",
    "    \n",
    "    for rd, pts, pred_winners, act_winners in zip(rounds, points, prediction, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred, act in zip(pred_winners, act_winners):\n",
    "            if (pred == act):\n",
    "                num_correct += 1\n",
    "        \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y, team_data) = load_data()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "tournament_results = [[1420, 1243, 1246, 1138, 1260, 1397, 1305, 1153, 1462, 1199, 1326, 1211, 1222, 1276, 1401, 1314, 1437, 1104, 1452, 1267, 1196, 1403, 1139, 1345, 1242, 1371, 1155, 1120, 1393, 1277, 1348, 1181],[1243, 1246, 1260, 1305, 1199, 1211, 1276, 1401, 1437, 1452, 1403, 1345, 1242, 1155, 1393, 1181],[1243, 1260, 1199, 1276, 1437, 1403, 1242, 1181],[1260, 1276, 1437, 1242],[1276, 1437],[1437]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2018]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BNB\", \"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "classifiers = [BernoulliNB(), \\\n",
    "            GaussianNB(), \\\n",
    "            LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "            LogisticRegression(), \\\n",
    "            SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            DecisionTreeClassifier(), \\\n",
    "            RandomForestClassifier(),  \\\n",
    "            BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "            GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "            MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "(baseline_losers, baseline_winners) = predict_bracket_baseline()\n",
    "baseline_winner = team_dict[baseline_winners[5][0]]\n",
    "baseline_espn_score = score_bracket_espn(tournament_results, baseline_winners)\n",
    "baseline_upset_score = score_bracket_upsets(tournament_results, baseline_winners, baseline_losers)\n",
    "results.append([\"Baseline\", baseline_winner, baseline_espn_score, baseline_upset_score])\n",
    "\n",
    "for m,c in zip(models,classifiers):\n",
    "    c.fit(train_X, train_Y)\n",
    "    (losers, winners) = predict_bracket(c)\n",
    "    \n",
    "    champion = team_dict[winners[5][0]]\n",
    "    espn_score = score_bracket_espn(tournament_results, winners)\n",
    "    upset_score = score_bracket_upsets(tournament_results, winners, losers)\n",
    "    \n",
    "    results.append([m, champion, espn_score, upset_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     Champion       ESPN Score    Upset Score\n",
      "--------  -----------  ------------  -------------\n",
      "Baseline  Kansas                650             65\n",
      "BNB       Iona                  130             58\n",
      "GNB       Michigan St           630             98\n",
      "LDA       Villanova            1200            165\n",
      "SVM_L     Villanova            1130            143\n",
      "5NN       Wichita St            430             63\n",
      "LR2       Villanova            1200            165\n",
      "SGD       Auburn                320             67\n",
      "ADA       Villanova            1590            234\n",
      "DT        Villanova            1920            292\n",
      "RF        Villanova            1920            292\n",
      "DPGMM     Syracuse              200             35\n",
      "ET        Villanova            1760            271\n",
      "GMM       Alabama               520            107\n",
      "MLP       Virginia              550             80\n"
     ]
    }
   ],
   "source": [
    "print tabulate.tabulate(results, headers=['Model', 'Champion', 'ESPN Score', 'Upset Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()\n",
    "#lr.fit(train_X, train_Y)\n",
    "#(losers, winners) = predict_bracket_upsets(lr)\n",
    "#upset_score = score_bracket_upsets(results, winners, losers)\n",
    "#print upset_score\n",
    "#espn_score = score_bracket_espn(results, winners)\n",
    "#print espn_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
