{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import tabulate\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier #RandomizedLasso\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.mixture import BayesianGaussianMixture, GaussianMixture\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(string_seed):\n",
    "    result = \"\"\n",
    "    for char in string_seed:\n",
    "        if char.isdigit():\n",
    "            result += char\n",
    "    return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2018():\n",
    "    ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "    ext_data_team = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR']\n",
    "    \n",
    "    train = pd.read_csv('train_2010_2017.csv')\n",
    "    #train = train.drop(labels=ext_data_matchups, axis=1)\n",
    "    #train['TeamSeed'] = train['TeamSeed'].apply(fix_seed)\n",
    "    #train['OppTeamSeed'] = train['OppTeamSeed'].apply(fix_seed)\n",
    "    \n",
    "    train_Y = train['Outcome']\n",
    "    train_X = train.drop(labels=['Outcome'], axis=1)\n",
    "    \n",
    "    team_data = pd.read_csv('team_info_2018.csv')\n",
    "    #team_data = team_data.drop(labels=ext_data_team, axis=1)\n",
    "    #team_data['Seed'] = team_data['Seed'].apply(fix_seed)\n",
    "    \n",
    "    return train_X, train_Y, team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2017():\n",
    "    ext_data_matchups = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR', 'OppPomeroyRank', 'OppConf', 'OppAdjEM', 'OppAdjO', 'OppAdjD', 'OppAdjT', 'OppLuck', 'OppSOSAdjEM', 'OppOppO', 'OppOppD', 'OppNCSOSAdjEM', 'OppMooreRank', 'OppMooreSOS', 'OppMoorePR']\n",
    "    ext_data_team = ['PomeroyRank', 'Conf', 'AdjEM', 'AdjO', 'AdjD', 'AdjT', 'Luck', 'SOSAdjEM', 'OppO', 'OppD', 'NCSOSAdjEM', 'MooreRank', 'MooreSOS', 'MoorePR']\n",
    "    \n",
    "    train = pd.read_csv('train_2010_2016.csv')\n",
    "    #train = train.drop(labels=ext_data_matchups, axis=1)\n",
    "    #train['TeamSeed'] = train['TeamSeed'].apply(fix_seed)\n",
    "    #train['OppTeamSeed'] = train['OppTeamSeed'].apply(fix_seed)\n",
    "    \n",
    "    train_Y = train['Outcome']\n",
    "    train_X = train.drop(labels=['Outcome'], axis=1)\n",
    "    \n",
    "    team_data = pd.read_csv('team_info_2017.csv')\n",
    "    #team_data = team_data.drop(labels=ext_data_team, axis=1)\n",
    "    #team_data['Seed'] = team_data['Seed'].apply(fix_seed)\n",
    "    \n",
    "    return train_X, train_Y, team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coef(lr):\n",
    "    adj = []\n",
    "    coefs = lr.coef_\n",
    "    for c in coefs[0]:\n",
    "        adj.append(math.exp(c))\n",
    "\n",
    "    features = pd.DataFrame(data=list(test_X))\n",
    "    weights = pd.DataFrame(data=adj)\n",
    "\n",
    "    feature_weights = pd.concat([features, weights], axis=1)\n",
    "    feature_weights.columns = ['Feature', 'Weight']\n",
    "    feature_weights = feature_weights.sort_values(by='Weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions for matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winners_to_matchups(winners):\n",
    "    matchups = []\n",
    "    for i in xrange(0,len(winners),2):\n",
    "        team1 = winners[i]\n",
    "        team2 = winners[i+1]\n",
    "        matchups.append([team1, team2])\n",
    "    return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matchups(team_data, pairings, rd, season):\n",
    "    opp_prefixes = ['Season', 'OppTeamID', 'OppW', 'OppL', 'OppAvgScore', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF', 'OppSeed']\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    df2 = pd.DataFrame()\n",
    "    \n",
    "    for p in pairings:        \n",
    "        team_1 = p[0]\n",
    "        team_1_data = team_data[(team_data['Season'] == season) & (team_data['TeamID'] == team_1)]\n",
    "        team_1_data_opp = team_1_data.copy()\n",
    "        team_1_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team_2 = p[1]\n",
    "        team_2_data = team_data[(team_data['Season'] == season) & (team_data['TeamID'] == team_2)]\n",
    "        team_2_data_opp = team_2_data.copy()\n",
    "        team_2_data_opp.columns = opp_prefixes\n",
    "        \n",
    "        team1_v_team2 = team_1_data.merge(team_2_data_opp, how='outer', on='Season')\n",
    "        team2_v_team1 = team_2_data.merge(team_1_data_opp, how='outer', on='Season')\n",
    "        \n",
    "        df1 = df1.append(team1_v_team2, ignore_index=True)\n",
    "        df2 = df2.append(team2_v_team1, ignore_index=True)\n",
    "        \n",
    "    df = df1.append(df2, ignore_index=True)\n",
    "    df['Round'] = rd\n",
    "    df = df.rename(columns={'Seed': 'TeamSeed', 'OppSeed': 'OppTeamSeed', 'AvgScore': 'AvgPoints', 'AvgOppScore': 'AvgOppPoints', 'OppAvgScore': 'OppAvgPoints'})\n",
    "    df = df[['Season', 'Round', 'TeamID', 'OppTeamID', 'TeamSeed', 'OppTeamSeed', 'W', 'L', 'AvgPoints', 'AvgFGM', 'AvgFGA', 'AvgFGM3', 'AvgFGA3', 'AvgFTM', 'AvgFTA', 'AvgOR', 'AvgDR', 'AvgAst', 'AvgTO', 'AvgStl', 'AvgBlk', 'AvgPF', 'AvgOppPoints', 'AvgOppFGM', 'AvgOppFGA', 'AvgOppFGM3', 'AvgOppFGA3', 'AvgOppFTM', 'AvgOppFTA', 'AvgOppOR', 'AvgOppDR', 'AvgOppAst', 'AvgOppTO', 'AvgOppStl', 'AvgOppBlk', 'AvgOppPF', 'OppW', 'OppL', 'OppAvgPoints', 'OppAvgFGM', 'OppAvgFGA', 'OppAvgFGM3', 'OppAvgFGA3', 'OppAvgFTM', 'OppAvgFTA', 'OppAvgOR', 'OppAvgDR', 'OppAvgAst', 'OppAvgTO', 'OppAvgStl', 'OppAvgBlk', 'OppAvgPF', 'OppAvgOppScore', 'OppAvgOppFGM', 'OppAvgOppFGA', 'OppAvgOppFGM3', 'OppAvgOppFGA3', 'OppAvgOppFTM', 'OppAvgOppFTA', 'OppAvgOppOR', 'OppAvgOppDR', 'OppAvgOppAst', 'OppAvgOppTO', 'OppAvgOppStl', 'OppAvgOppBlk', 'OppAvgOppPF']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline predictor - always pick higher seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_predictor(matchups):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for m in matchups:\n",
    "        team1 = m[0]\n",
    "        team2 = m[1]\n",
    "        \n",
    "        seed1 = seeds_dict[team1]\n",
    "        seed2 = seeds_dict[team2]\n",
    "        \n",
    "        if (seed1 < seed2):\n",
    "            winners.append(team1)\n",
    "            losers.append(team2)\n",
    "        else:\n",
    "            winners.append(team2)\n",
    "            losers.append(team1)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_baseline(matchups):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        (loser_ids, winner_ids) = baseline_predictor(matchups)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "        \n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "            \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal probability-based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_prob(classifier, matchups):\n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "\n",
    "    # make predictions\n",
    "    results_concat['Team1WinPred'] = np.where(results_concat['Win1Adj'] > results_concat['Win2Adj'], 1, 0)\n",
    "    # print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1WinPred'] == 1, results_concat['Team2'], results_concat['Team1'])\n",
    "    return pred_losers, pred_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket(team_data, matchups, classifier, season):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r, season)\n",
    "        (loser_ids, winner_ids) = predict_with_prob(classifier, matchups_with_data)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction with upset bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_upset_bonus(classifier, matchups, round_num):\n",
    "    points = {1:1, 2:2, 3:4, 4:8, 5:16, 6:32}\n",
    "    upset_bonus = 2\n",
    "    round_points = points[round_num]\n",
    "    \n",
    "    split = len(matchups) / 2\n",
    "    \n",
    "    # get win probabilities\n",
    "    teams = matchups[['TeamID', 'OppTeamID']]\n",
    "    win_probs = pd.DataFrame(data=classifier.predict_proba(matchups), columns=['Loss', 'Win'])\n",
    "    results = pd.concat([teams, win_probs], axis=1)\n",
    "\n",
    "    # compare predictions for each matchup from each POV\n",
    "    results_1 = results.iloc[:split]\n",
    "    results_1.loc[:,'Matchup'] = results_1.index\n",
    "    results_2 = results.iloc[split:].reset_index()\n",
    "    results_2.loc[:,'Matchup'] = results_2.index\n",
    "    results_concat = results_1.join(results_2, on='Matchup', lsuffix='1', rsuffix='2')\n",
    "    results_concat = results_concat[['TeamID1', 'OppTeamID1', 'Win1', 'Win2']]\n",
    "    results_concat.columns = ['Team1', 'Team2', 'Win1', 'Win2']\n",
    "    \n",
    "    # standardize probabilities\n",
    "    results_concat['Sum'] = results_concat['Win1'] + results_concat['Win2']\n",
    "    results_concat['Win1Adj'] = results_concat['Win1'] / results_concat['Sum']\n",
    "    results_concat['Win2Adj'] = results_concat['Win2'] / results_concat['Sum']\n",
    "    \n",
    "    # calculate expected values\n",
    "    results_concat['Team1Seed'] = results_concat['Team1'].map(seeds_dict)\n",
    "    results_concat['Team2Seed'] = results_concat['Team2'].map(seeds_dict)\n",
    "    \n",
    "    results_concat['Team1WinVal'] = np.where(results_concat['Team1Seed'] > results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    results_concat['Team2WinVal'] = np.where(results_concat['Team1Seed'] < results_concat['Team2Seed'], round_points + upset_bonus, round_points)\n",
    "    \n",
    "    results_concat['Team1ExpVal'] = results_concat['Win1Adj'] * results_concat['Team1WinVal']\n",
    "    results_concat['Team2ExpVal'] = results_concat['Win2Adj'] * results_concat['Team2WinVal']\n",
    "    \n",
    "    #results_concat = results_concat[['Team1', 'Win1Adj', 'Team1Seed', 'Team1WinVal', 'Team1ExpVal', 'Team2', 'Win2Adj', 'Team2Seed', 'Team2WinVal', 'Team2ExpVal']]\n",
    "    #print results_concat\n",
    "    \n",
    "    pred_winners = np.where(results_concat['Team1ExpVal'] > results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    pred_losers = np.where(results_concat['Team1ExpVal'] < results_concat['Team2ExpVal'], results_concat['Team1'], results_concat['Team2'])\n",
    "    return pred_winners, pred_losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_upsets(team_data, matchups, classifier, season):\n",
    "    winners = []\n",
    "    losers = []\n",
    "    \n",
    "    for r in rounds:\n",
    "        matchups_with_data = create_matchups(team_data, matchups, r, season)\n",
    "        (loser_ids, winner_ids) = predict_with_upset_bonus(classifier, matchups_with_data, r)\n",
    "        winners.append(winner_ids)\n",
    "        losers.append(loser_ids)\n",
    "        winner_names = [team_dict[team_id] for team_id in winner_ids]\n",
    "        #print winner_names\n",
    "        #print\n",
    "\n",
    "        if (r < 6):\n",
    "            matchups = winners_to_matchups(winner_ids)\n",
    "    \n",
    "    return losers, winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_upsets(results, pred_winners, pred_losers):\n",
    "    # see https://www.nytimes.com/2015/03/16/upshot/heres-how-our-ncaa-bracket-works.html\n",
    "    points = [1, 2, 4, 8, 16, 32]\n",
    "    total_pts = 0\n",
    "    upset_bonus = 5\n",
    "    num_upsets = 0\n",
    "    \n",
    "    for rd, pts, pred_win, pred_lose, act_win in zip(rounds, points, pred_winners, pred_losers, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred_w, pred_l, act_w in zip(pred_win, pred_lose, act_win):\n",
    "            if (pred_w == act_w):\n",
    "                num_correct += 1\n",
    "                if (seeds_dict[pred_w] > seeds_dict[pred_l]):\n",
    "                    num_upsets += 1\n",
    "                \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    total_pts += (num_upsets * upset_bonus)\n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bracket_espn(results, prediction):\n",
    "    # see http://games.espn.com/tournament-challenge-bracket/2018/en/story?pageName=tcmen%5Chowtoplay\n",
    "    points = [10, 20, 40, 80, 160, 320]\n",
    "    total_pts = 0\n",
    "    \n",
    "    for rd, pts, pred_winners, act_winners in zip(rounds, points, prediction, results):\n",
    "        num_correct = 0\n",
    "        \n",
    "        for pred, act in zip(pred_winners, act_winners):\n",
    "            if (pred == act):\n",
    "                num_correct += 1\n",
    "        \n",
    "        rd_pts = pts * num_correct\n",
    "        total_pts += rd_pts\n",
    "    \n",
    "    return total_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_Y, team_data) = load_data_2018()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "matchups = [[1438,1420], [1166, 1243], [1246, 1172], [1112, 1138], [1274, 1260], [1397, 1460], [1305, 1400], [1153, 1209], [1462, 1411], [1281, 1199], [1326, 1355], [1211, 1422], [1222, 1361], [1276, 1285], [1401, 1344], [1314, 1252], [1437, 1347], [1439, 1104], [1452, 1293], [1455, 1267], [1196, 1382], [1403, 1372], [1116, 1139], [1345, 1168], [1242, 1335], [1371, 1301], [1155, 1308], [1120, 1158], [1395, 1393], [1277, 1137], [1348, 1328], [1181, 1233]]    \n",
    "tournament_results = [[1420, 1243, 1246, 1138, 1260, 1397, 1305, 1153, 1462, 1199, 1326, 1211, 1222, 1276, 1401, 1314, 1437, 1104, 1452, 1267, 1196, 1403, 1139, 1345, 1242, 1371, 1155, 1120, 1393, 1277, 1348, 1181],[1243, 1246, 1260, 1305, 1199, 1211, 1276, 1401, 1437, 1452, 1403, 1345, 1242, 1155, 1393, 1181],[1243, 1260, 1199, 1276, 1437, 1403, 1242, 1181],[1260, 1276, 1437, 1242],[1276, 1437],[1437]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2018]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BNB\", \"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "classifiers = [BernoulliNB(), \\\n",
    "            GaussianNB(), \\\n",
    "            LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "            LogisticRegression(), \\\n",
    "            SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            DecisionTreeClassifier(), \\\n",
    "            RandomForestClassifier(),  \\\n",
    "            BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "            GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "            MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "(baseline_losers, baseline_winners) = predict_bracket_baseline(matchups)\n",
    "baseline_winner = team_dict[baseline_winners[5][0]]\n",
    "baseline_espn_score = score_bracket_espn(tournament_results, baseline_winners)\n",
    "baseline_upset_score = score_bracket_upsets(tournament_results, baseline_winners, baseline_losers)\n",
    "results.append([\"Baseline\", baseline_winner, baseline_espn_score, baseline_upset_score])\n",
    "\n",
    "for m,c in zip(models,classifiers):\n",
    "    c.fit(train_X, train_Y)\n",
    "    (losers, winners) = predict_bracket(team_data, matchups, c, 2018)\n",
    "    \n",
    "    champion = team_dict[winners[5][0]]\n",
    "    espn_score = score_bracket_espn(tournament_results, winners)\n",
    "    upset_score = score_bracket_upsets(tournament_results, winners, losers)\n",
    "    \n",
    "    results.append([m, champion, espn_score, upset_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     Champion          ESPN Score    Upset Score\n",
      "--------  --------------  ------------  -------------\n",
      "Baseline  Kansas                   650             65\n",
      "BNB       Iona                     130             58\n",
      "GNB       Michigan St              560             91\n",
      "LDA       Cincinnati               800            120\n",
      "SVM_L     Villanova               1080            143\n",
      "5NN       Virginia                 220             37\n",
      "LR2       Villanova               1120            152\n",
      "SGD       Duke                     310             71\n",
      "ADA       Gonzaga                  520             87\n",
      "DT        Texas Tech               480             98\n",
      "RF        Cincinnati               470             67\n",
      "DPGMM     North Carolina           180             38\n",
      "ET        Kansas                   500             75\n",
      "GMM       Bucknell                 370             92\n",
      "MLP       Cincinnati               450             55\n"
     ]
    }
   ],
   "source": [
    "print tabulate.tabulate(results, headers=['Model', 'Champion', 'ESPN Score', 'Upset Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr = LogisticRegression()\n",
    "#lr.fit(train_X, train_Y)\n",
    "#(losers, winners) = predict_bracket_upsets(team_data, matchups, lr, 2018)\n",
    "#upset_score = score_bracket_upsets(results, winners, losers)\n",
    "#print upset_score\n",
    "#espn_score = score_bracket_espn(results, winners)\n",
    "#print espn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X_2017, train_Y_2017, team_data_2017) = load_data_2017()\n",
    "teams = pd.read_csv('DataFiles/Teams.csv')\n",
    "team_dict = pd.Series(teams.TeamName.values,index=teams.TeamID).to_dict()\n",
    "rounds = [1, 2, 3, 4, 5, 6]\n",
    "matchups_2017 = [[1437, 1291], [1458, 1439], [1438, 1423], [1196, 1190], [1374, 1425], [1124, 1308], [1376, 1266], [1181, 1407], [1211, 1355], [1321, 1435], [1323, 1343], [1452, 1137], [1268, 1462], [1199, 1195], [1388, 1433], [1112, 1315], [1242, 1413], [1274, 1277], [1235, 1305], [1345, 1436], [1166, 1348], [1332, 1233], [1276, 1329], [1257, 1240], [1314, 1411], [1116, 1371], [1278, 1292], [1139, 1457], [1153, 1243], [1417, 1245], [1173, 1455], [1246, 1297]]\n",
    "results_2017 = [[1437, 1458, 1438, 1196, 1425, 1124, 1376, 1181, 1211, 1321, 1323, 1452, 1462, 1199, 1388, 1112, 1242, 1277, 1235, 1345, 1348, 1332, 1276, 1257, 1314, 1116, 1292, 1139, 1153, 1417, 1455, 1246], [1458, 1196, 1124, 1376, 1211, 1452, 1462, 1112, 1242, 1345, 1332, 1276, 1314, 1139, 1417, 1246], [1196, 1376, 1211, 1462, 1242, 1332, 1314, 1246], [1376, 1211, 1332, 1314], [1211, 1314], [1314]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('Stage2UpdatedDataFiles/NCAATourneySeeds.csv')\n",
    "seeds = seeds[seeds['Season'] == 2017]\n",
    "seeds['Seed'] = seeds['Seed'].apply(fix_seed)\n",
    "\n",
    "seeds_dict = pd.Series(seeds.Seed.values,index=seeds.TeamID).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"BNB\", \"GNB\", \"LDA\",\"SVM_L\", \"5NN\", \"LR2\", \"SGD\",\"ADA\", \"DT\", \"RF\", \"DPGMM\", \"ET\", \"GMM\", \"MLP\"] #\"SVM_L\", \"SVM_G\", \"P2\", \"DT\",  \"ADA_R\", \n",
    "classifiers = [BernoulliNB(), \\\n",
    "            GaussianNB(), \\\n",
    "            LinearDiscriminantAnalysis(), \\\n",
    "            svm.SVC(kernel = 'linear', probability=True), \\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=5), \\\n",
    "            LogisticRegression(), \\\n",
    "            SGDClassifier(loss='log', tol=0.0001, power_t=0.4, average=True), \\\n",
    "            AdaBoostClassifier(base_estimator=None, n_estimators=100), \\\n",
    "            DecisionTreeClassifier(), \\\n",
    "            RandomForestClassifier(),  \\\n",
    "            BayesianGaussianMixture(n_components=2,max_iter=1000, weight_concentration_prior_type='dirichlet_process', tol=0.0001), \\\n",
    "            ExtraTreesClassifier(bootstrap=True, n_estimators=4), \\\n",
    "            GaussianMixture(n_components=2, tol=0.0001, max_iter=1000, n_init=2), \\\n",
    "            MLPClassifier(activation='relu', alpha=0.00001, max_iter=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "(baseline_losers, baseline_winners) = predict_bracket_baseline(matchups_2017)\n",
    "baseline_winner = team_dict[baseline_winners[5][0]]\n",
    "baseline_espn_score = score_bracket_espn(results_2017, baseline_winners)\n",
    "baseline_upset_score = score_bracket_upsets(results_2017, baseline_winners, baseline_losers)\n",
    "results.append([\"Baseline\", baseline_winner, baseline_espn_score, baseline_upset_score])\n",
    "\n",
    "for m,c in zip(models,classifiers):\n",
    "    c.fit(train_X_2017, train_Y_2017)\n",
    "    (losers, winners) = predict_bracket(team_data_2017, matchups_2017, c, 2017)\n",
    "    \n",
    "    champion = team_dict[winners[5][0]]\n",
    "    espn_score = score_bracket_espn(results_2017, winners)\n",
    "    upset_score = score_bracket_upsets(results_2017, winners, losers)\n",
    "    \n",
    "    results.append([m, champion, espn_score, upset_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     Champion          ESPN Score    Upset Score\n",
      "--------  --------------  ------------  -------------\n",
      "Baseline  North Carolina             0              0\n",
      "BNB       N Kentucky                60             36\n",
      "GNB       Gonzaga                  810             96\n",
      "LDA       Villanova                530             68\n",
      "SVM_L     Villanova                750             95\n",
      "5NN       Notre Dame               340             49\n",
      "LR2       Villanova                730             93\n",
      "SGD       Butler                   180             33\n",
      "ADA       Villanova                780             98\n",
      "DT        UCLA                     740             99\n",
      "RF        Wichita St               650             90\n",
      "DPGMM     Butler                   370             47\n",
      "ET        Villanova                300             45\n",
      "GMM       UC Davis                 250             60\n",
      "MLP       SMU                      640             84\n"
     ]
    }
   ],
   "source": [
    "print tabulate.tabulate(results, headers=['Model', 'Champion', 'ESPN Score', 'Upset Score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
